{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Resources Analytics Dataset Analysis\n",
    "\n",
    "Module: CS985: Machine Learning For Data Analytics\n",
    "\n",
    "Student: Rokas Labeikis\n",
    "\n",
    "Student ID: 201349799\n",
    "\n",
    "## Objective and problem\n",
    "\n",
    "\n",
    "## Introduction to the dataset\n",
    "\n",
    "\n",
    "## Obtaining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rokas/anaconda2/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/home/rokas/anaconda2/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/home/rokas/anaconda2/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/home/rokas/anaconda2/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "warnings.resetwarnings()\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TensorFlow version: ', '1.7.0')\n",
      "('Python version: ', '2.7.13')\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version: ', tf.__version__)\n",
    "print('Python version: ', platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = Path('input/training/')\n",
    "test_dir = Path('input/validation/')\n",
    "test_file = './input/test-paths-labels.csv'\n",
    "train_file = './input/train-paths-labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Latin Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Train Images</th>\n",
       "      <th>Validation Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>alouatta_palliata\\t</td>\n",
       "      <td>mantled_howler</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>erythrocebus_patas\\t</td>\n",
       "      <td>patas_monkey</td>\n",
       "      <td>139</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>cacajao_calvus\\t</td>\n",
       "      <td>bald_uakari</td>\n",
       "      <td>137</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>macaca_fuscata\\t</td>\n",
       "      <td>japanese_macaque</td>\n",
       "      <td>152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>cebuella_pygmea\\t</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>cebus_capucinus\\t</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "      <td>141</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>mico_argentatus\\t</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>saimiri_sciureus\\t</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "      <td>142</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>aotus_nigriceps\\t</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>trachypithecus_johnii</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                Latin Name                      Common Name  \\\n",
       "0  n0         alouatta_palliata\\t    mantled_howler                   \n",
       "1  n1        erythrocebus_patas\\t    patas_monkey                     \n",
       "2  n2        cacajao_calvus\\t        bald_uakari                      \n",
       "3  n3        macaca_fuscata\\t        japanese_macaque                 \n",
       "4  n4       cebuella_pygmea\\t        pygmy_marmoset                   \n",
       "5  n5       cebus_capucinus\\t        white_headed_capuchin            \n",
       "6  n6       mico_argentatus\\t        silvery_marmoset                 \n",
       "7  n7      saimiri_sciureus\\t        common_squirrel_monkey           \n",
       "8  n8       aotus_nigriceps\\t        black_headed_night_monkey        \n",
       "9  n9       trachypithecus_johnii    nilgiri_langur                   \n",
       "\n",
       "   Train Images  Validation Images  \n",
       "0           131                 26  \n",
       "1           139                 28  \n",
       "2           137                 27  \n",
       "3           152                 30  \n",
       "4           131                 26  \n",
       "5           141                 28  \n",
       "6           132                 26  \n",
       "7           142                 28  \n",
       "8           133                 27  \n",
       "9           132                 26  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label info\n",
    "info = pd.read_csv(\"input/monkey_labels.txt\", names=['Label','Latin Name', 'Common Name','Train Images', 'Validation Images'], skiprows=1)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    images = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for training_dir_path in glob.glob(filename + \"/*\"):\n",
    "        label = info[\"Common Name\"][i].rstrip()\n",
    "        i=i+1\n",
    "        for image_path in glob.glob(os.path.join(training_dir_path, \"*.jpg\")):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (1, 1))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "            labels.append(label)\n",
    "            images.append(image)\n",
    "            paths.append(image_path)\n",
    "            \n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(labels)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    i_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    d = {'images':images,'labels':labels, 'int':integer_encoded, 'hot': onehot_encoded.tolist()}\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "train = read_data(\"input/training\")\n",
    "test = read_data(\"input/validation\")\n",
    "train.to_csv('./input/train.csv', index=False) \n",
    "test.to_csv('./input/test.csv',  index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know images are 150 by 150 \n",
    "img_size = 150\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 10\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i])\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# Get the first images from the test-set.\n",
    "images = train[\"images\"][0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = train[\"labels\"][0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-69e5324cc13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# Sample image\n",
    "plt.imshow(train[\"images\"][200])\n",
    "plt.show()\n",
    "print(train[\"labels\"][200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model\n",
    "\n",
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bald_uakari', 0.95616525)\n",
      "('japanese_macaque', 0.02068729)\n",
      "('nilgiri_langur', 0.007473636)\n",
      "('common_squirrel_monkey', 0.0067563313)\n",
      "('black_headed_night_monkey', 0.0023083456)\n"
     ]
    }
   ],
   "source": [
    "# python label_image.py --graph=retrained_model/output_graph.pb --labels=retrained_model/output_labels.txt --input_layer=Placeholder --output_layer=final_result --image=input/validation/n9/n901.jpg\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "   \n",
    "    image_reader = tf.image.decode_jpeg(file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    \n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "    \n",
    "    return result\n",
    "\n",
    "model_file = 'retrained_model/output_graph.pb'\n",
    "label_file = 'retrained_model/output_labels.txt'\n",
    "input_layer = 'Placeholder'\n",
    "output_layer = 'final_result'\n",
    "\n",
    "#load graph\n",
    "graph = tf.Graph()\n",
    "graph_def = tf.GraphDef()\n",
    "with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "t = read_tensor_from_image_file('input/validation/n2/n201.jpg')\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "labels = load_labels(label_file)\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_labelled_input_fn(input_file, batch_size):\n",
    "    def input_fn():\n",
    "        def read_labeled_image_list(image_list_file):\n",
    "            df = pd.read_csv(image_list_file)\n",
    "            return df[\"path\"].tolist(), df[\"int\"].tolist()\n",
    "\n",
    "        image_list, label_list = read_labeled_image_list(input_file)\n",
    "\n",
    "        def read_images_from_disk(input_queue):\n",
    "            label = input_queue[1]\n",
    "            file_contents = tf.read_file(input_queue[0])\n",
    "            example = tf.image.decode_jpeg(file_contents, channels=3)\n",
    "            example=tf.image.resize_images(example, [150, 150])\n",
    "            example=tf.reshape(example, [150, 150, 3]) \n",
    "            return example, label\n",
    "\n",
    "        images = tf.convert_to_tensor(image_list, dtype=tf.string)\n",
    "        labels = tf.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "\n",
    "        # Makes an input queue\n",
    "        input_queue = tf.train.slice_input_producer([images, labels], shuffle=True)\n",
    "\n",
    "        image, label = read_images_from_disk(input_queue)\n",
    "        image_batch, label_batch = tf.train.batch([image, label], batch_size=batch_size)\n",
    "        return {'images':  image_batch}, label_batch\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f221178b4d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './linear_model', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# image_arrays = np.asarray(train['images'], dtype=np.float32).reshape((1, 1))\n",
    "feature_columns = [tf.feature_column.numeric_column('images', shape=[150,150,3])]\n",
    "\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=10,\n",
    "    model_dir='./linear_model'\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 40\n",
    "TRAIN_STEPS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./linear_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 92.10341, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.50712\n",
      "INFO:tensorflow:loss = 2125745.5, step = 101 (66.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4876\n",
      "INFO:tensorflow:loss = 1353128.0, step = 201 (67.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.27107\n",
      "INFO:tensorflow:loss = 590059.5, step = 301 (78.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33276\n",
      "INFO:tensorflow:loss = 272023.0, step = 401 (75.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.19312\n",
      "INFO:tensorflow:loss = 216931.0, step = 501 (83.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.22351\n",
      "INFO:tensorflow:loss = 277782.25, step = 601 (81.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.21044\n",
      "INFO:tensorflow:loss = 123062.0, step = 701 (82.613 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 787 into ./linear_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32857\n",
      "INFO:tensorflow:loss = 35204.125, step = 801 (75.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.20792\n",
      "INFO:tensorflow:loss = 48718.0, step = 901 (82.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.19148\n",
      "INFO:tensorflow:loss = 0.0, step = 1001 (83.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.28424\n",
      "INFO:tensorflow:loss = 47.0, step = 1101 (77.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.11868\n",
      "INFO:tensorflow:loss = 38427.125, step = 1201 (89.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.25454\n",
      "INFO:tensorflow:loss = 0.0, step = 1301 (79.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.06215\n",
      "INFO:tensorflow:loss = 0.0, step = 1401 (94.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.37396\n",
      "INFO:tensorflow:loss = 0.0, step = 1501 (72.781 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1515 into ./linear_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.25785\n",
      "INFO:tensorflow:loss = 0.0, step = 1601 (79.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.40154\n",
      "INFO:tensorflow:loss = 0.0, step = 1701 (71.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43834\n",
      "INFO:tensorflow:loss = 0.0, step = 1801 (69.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43424\n",
      "INFO:tensorflow:loss = 0.0, step = 1901 (69.725 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./linear_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f22087f3690>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=generate_labelled_input_fn('./input/train-paths-labels.csv', BATCH_SIZE),\n",
    "    steps=TRAIN_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-11-16:56:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./linear_model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-11-16:57:28\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.54725, average_loss = 14453.339, global_step = 2000, loss = 578133.56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.54725,\n",
       " 'average_loss': 14453.339,\n",
       " 'global_step': 2000,\n",
       " 'loss': 578133.56}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(\n",
    "    input_fn=generate_labelled_input_fn('./input/test-paths-labels.csv', BATCH_SIZE),\n",
    "    steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
