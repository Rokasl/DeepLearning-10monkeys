{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Resources Analytics Dataset Analysis\n",
    "\n",
    "Module: CS985: Machine Learning For Data Analytics\n",
    "\n",
    "Student: Rokas Labeikis\n",
    "\n",
    "Student ID: 201349799\n",
    "\n",
    "## Objective and problem\n",
    "\n",
    "\n",
    "## Introduction to the dataset\n",
    "\n",
    "\n",
    "## Obtaining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rokas/anaconda2/lib/python2.7/site-packages/sklearn/utils/__init__.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/home/rokas/anaconda2/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n",
      "/home/rokas/anaconda2/lib/python2.7/site-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/home/rokas/anaconda2/lib/python2.7/site-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "warnings.resetwarnings()\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import platform\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TensorFlow version: ', '1.7.0')\n",
      "('Python version: ', '2.7.13')\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version: ', tf.__version__)\n",
    "print('Python version: ', platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = Path('input/training/')\n",
    "test_dir = Path('input/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Latin Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Train Images</th>\n",
       "      <th>Validation Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>alouatta_palliata\\t</td>\n",
       "      <td>mantled_howler</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>erythrocebus_patas\\t</td>\n",
       "      <td>patas_monkey</td>\n",
       "      <td>139</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>cacajao_calvus\\t</td>\n",
       "      <td>bald_uakari</td>\n",
       "      <td>137</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>macaca_fuscata\\t</td>\n",
       "      <td>japanese_macaque</td>\n",
       "      <td>152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>cebuella_pygmea\\t</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>cebus_capucinus\\t</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "      <td>141</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>mico_argentatus\\t</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>saimiri_sciureus\\t</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "      <td>142</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>aotus_nigriceps\\t</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>trachypithecus_johnii</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                Latin Name                      Common Name  \\\n",
       "0  n0         alouatta_palliata\\t    mantled_howler                   \n",
       "1  n1        erythrocebus_patas\\t    patas_monkey                     \n",
       "2  n2        cacajao_calvus\\t        bald_uakari                      \n",
       "3  n3        macaca_fuscata\\t        japanese_macaque                 \n",
       "4  n4       cebuella_pygmea\\t        pygmy_marmoset                   \n",
       "5  n5       cebus_capucinus\\t        white_headed_capuchin            \n",
       "6  n6       mico_argentatus\\t        silvery_marmoset                 \n",
       "7  n7      saimiri_sciureus\\t        common_squirrel_monkey           \n",
       "8  n8       aotus_nigriceps\\t        black_headed_night_monkey        \n",
       "9  n9       trachypithecus_johnii    nilgiri_langur                   \n",
       "\n",
       "   Train Images  Validation Images  \n",
       "0           131                 26  \n",
       "1           139                 28  \n",
       "2           137                 27  \n",
       "3           152                 30  \n",
       "4           131                 26  \n",
       "5           141                 28  \n",
       "6           132                 26  \n",
       "7           142                 28  \n",
       "8           133                 27  \n",
       "9           132                 26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label info\n",
    "info = pd.read_csv(\"input/monkey_labels.txt\", names=['Label','Latin Name', 'Common Name','Train Images', 'Validation Images'], skiprows=1)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    images = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for training_dir_path in glob.glob(filename + \"/*\"):\n",
    "        label = training_dir_path.split(\"/\")[-1]\n",
    "        for image_path in glob.glob(os.path.join(training_dir_path, \"*.jpg\")):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (1, 1))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            labels.append(label)\n",
    "            images.append(image)\n",
    "            paths.append(image_path)\n",
    "            \n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(labels)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    i_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(i_encoded)\n",
    "    \n",
    "    d = {'images':images,'labels':labels, 'path': paths, 'int':integer_encoded, 'hot': onehot_encoded.tolist()}\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "train = read_data(\"input/training\")\n",
    "test = read_data(\"input/validation\")\n",
    "train.to_csv('./input/train.csv', index=False) \n",
    "test.to_csv('./input/test.csv',  index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know images are 150 by 150 \n",
    "img_size = 150\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 10\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i])\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# Get the first images from the test-set.\n",
    "images = train[\"images\"][0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = train[\"labels\"][0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-69e5324cc13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# Sample image\n",
    "plt.imshow(train[\"images\"][200])\n",
    "plt.show()\n",
    "print(train[\"labels\"][200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model\n",
    "\n",
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n1', 0.99499714, 'Correct!')\n",
      "('n7', 0.9958555, 'Correct!')\n",
      "('n6', 0.9874325, 'Correct!')\n",
      "('n3', 0.978956, 'Correct!')\n",
      "('n5', 0.99827945, 'Correct!')\n",
      "('n6', 0.96657157, 'Correct!')\n",
      "('n7', 0.9926466, 'Correct!')\n",
      "('n5', 0.9963971, 'Correct!')\n",
      "('n2', 0.9078938, 'Correct!')\n",
      "('n1', 0.99499714, 'Correct!')\n",
      "('n0', 0.99846387, 'Correct!')\n",
      "('n1', 0.92250466, 'Correct!')\n",
      "('n8', 0.99902844, 'Correct!')\n",
      "('n4', 0.95408446, 'Correct!')\n",
      "('n7', 0.983564, 'Correct!')\n",
      "('n0', 0.99984777, 'Correct!')\n",
      "('n2', 0.99017286, 'Correct!')\n",
      "('n5', 0.9656844, 'Correct!')\n",
      "('n9', 0.9427001, 'Correct!')\n",
      "('n3', 0.91738963, 'Correct!')\n",
      "('n6', 0.9933854, 'Correct!')\n",
      "('n8', 0.9983078, 'Correct!')\n",
      "('n3', 0.9998202, 'Correct!')\n",
      "('n9', 0.9985574, 'Correct!')\n",
      "('n1', 0.99181753, 'Correct!')\n",
      "('n1', 0.9928041, 'Correct!')\n",
      "('n9', 0.9948605, 'Correct!')\n",
      "('n0', 0.9980363, 'Correct!')\n",
      "('n6', 0.9931766, 'Correct!')\n",
      "('n8', 0.95426494, 'Correct!')\n",
      "('n5', 0.98561585, 'Correct!')\n",
      "('n8', 0.99942183, 'Correct!')\n",
      "('n9', 0.9328075, 'Correct!')\n",
      "('n3', 0.99068004, 'Correct!')\n",
      "('n3', 0.99876297, 'Correct!')\n",
      "('n7', 0.98138386, 'Correct!')\n",
      "('n6', 0.99725795, 'Correct!')\n",
      "('n8', 0.95493245, 'Correct!')\n",
      "('n9', 0.9982712, 'Correct!')\n",
      "('n8', 0.99836046, 'Correct!')\n",
      "('n2', 0.9798202, 'Correct!')\n",
      "('n4', 0.9978346, 'Correct!')\n",
      "('n2', 0.90155524, 'Correct!')\n",
      "('n2', 0.99307775, 'Correct!')\n",
      "('n7', 0.9893579, 'Correct!')\n",
      "('n6', 0.99316025, 'Correct!')\n",
      "('n2', 0.991376, 'Correct!')\n",
      "('n1', 0.99983263, 'Correct!')\n",
      "('n2', 0.9919585, 'Correct!')\n",
      "('n1', 0.9990539, 'Correct!')\n",
      "('n2', 0.9868662, 'Correct!')\n",
      "('n0', 0.99784434, 'Correct!')\n",
      "('n1', 0.9414028, 'Correct!')\n",
      "('n0', 0.99883157, 'Correct!')\n",
      "('n4', 0.98901844, 'Correct!')\n",
      "('n9', 0.99978715, 'Correct!')\n",
      "('n3', 0.9613882, 'Correct!')\n",
      "('n6', 0.9862213, 'Correct!')\n",
      "('n4', 0.9826324, 'Correct!')\n",
      "('n3', 0.9959925, 'Correct!')\n",
      "('n8', 0.69780123, 'Correct!')\n",
      "('n3', 0.99618983, 'Correct!')\n",
      "('n5', 0.9948907, 'Correct!')\n",
      "('n5', 0.9656844, 'Correct!')\n",
      "('n9', 0.9745361, 'Correct!')\n",
      "('n5', 0.9991825, 'Correct!')\n",
      "('n2', 0.9728319, 'Correct!')\n",
      "('n0', 0.99976987, 'Correct!')\n",
      "('n7', 0.9975823, 'Correct!')\n",
      "('n3', 0.9936706, 'Correct!')\n",
      "('n8', 0.99835336, 'Correct!')\n",
      "('n3', 0.9714076, 'Correct!')\n",
      "('n1', 0.9955812, 'Correct!')\n",
      "('n8', 0.99877673, 'Correct!')\n",
      "('n8', 0.96788156, 'Correct!')\n",
      "('n9', 0.99851114, 'Correct!')\n",
      "('n7', 0.9982743, 'Correct!')\n",
      "('n4', 0.987281, 'Correct!')\n",
      "('n5', 0.91539156, 'Correct!')\n",
      "('n0', 0.99854314, 'Correct!')\n",
      "('n9', 0.9893824, 'Correct!')\n",
      "('n8', 0.99535733, 'Correct!')\n",
      "('n9', 0.9898683, 'Correct!')\n",
      "('n3', 0.71840626, 'Correct!')\n",
      "('n7', 0.9897397, 'Correct!')\n",
      "('n7', 0.98530245, 'Correct!')\n",
      "('n0', 0.9836023, 'Correct!')\n",
      "('n3', 0.99478275, 'Correct!')\n",
      "('n4', 0.9976826, 'Correct!')\n",
      "('n9', 0.97409123, 'Correct!')\n",
      "('n7', 0.98754543, 'Correct!')\n",
      "('n5', 0.9974246, 'Correct!')\n",
      "('n5', 0.9973953, 'Correct!')\n",
      "('n4', 0.98490036, 'Correct!')\n",
      "('n0', 0.966275, 'Correct!')\n",
      "('n7', 0.9967836, 'Correct!')\n",
      "('n6', 0.98291934, 'Correct!')\n",
      "('n1', 0.9954367, 'Correct!')\n",
      "('n8', 0.9966987, 'Correct!')\n",
      "('n9', 0.9658403, 'Correct!')\n",
      "('n3', 0.9991844, 'Correct!')\n",
      "('n2', 0.9514423, 'Correct!')\n",
      "('n1', 0.9989085, 'Correct!')\n",
      "('n9', 0.99556124, 'Correct!')\n",
      "('n2', 0.9048977, 'Correct!')\n",
      "('n3', 0.99067616, 'Correct!')\n",
      "('n3', 0.9747661, 'Correct!')\n",
      "('n8', 0.9979867, 'Correct!')\n",
      "('n6', 0.84626085, 'Correct!')\n",
      "('n9', 0.9712577, 'Correct!')\n",
      "('n2', 0.95616525, 'Correct!')\n",
      "('n6', 0.9898173, 'Correct!')\n",
      "('n1', 0.9996847, 'Correct!')\n",
      "('n9', 0.9960997, 'Correct!')\n",
      "('n1', 0.999902, 'Correct!')\n",
      "('n2', 0.9789438, 'Correct!')\n",
      "('n4', 0.9970003, 'Correct!')\n",
      "('n3', 0.99857223, 'Correct!')\n",
      "('n6', 0.9017547, 'Correct!')\n",
      "('n8', 0.99911076, 'Correct!')\n",
      "('n1', 0.99972767, 'Correct!')\n",
      "('n3', 0.97580534, 'Correct!')\n",
      "('n2', 0.76783943, 'Correct!')\n",
      "('n5', 0.99494606, 'Correct!')\n",
      "('n1', 0.98489916, 'Correct!')\n",
      "('n1', 0.99988747, 'Correct!')\n",
      "('n1', 0.999705, 'Correct!')\n",
      "('n0', 0.9994771, 'Correct!')\n",
      "('n5', 0.98120433, 'Correct!')\n",
      "('n6', 0.9991861, 'Correct!')\n",
      "('n7', 0.9980416, 'Correct!')\n",
      "('n8', 0.9833994, 'Correct!')\n",
      "('n1', 0.9993968, 'Correct!')\n",
      "('n0', 0.99981743, 'Correct!')\n",
      "('n2', 0.9942426, 'Correct!')\n",
      "('n6', 0.9691245, 'Correct!')\n",
      "('n9', 0.99970514, 'Correct!')\n",
      "('n7', 0.99681145, 'Correct!')\n",
      "('n4', 0.9716442, 'Correct!')\n",
      "('n5', 0.9983993, 'Correct!')\n",
      "('n3', 0.97424316, 'Correct!')\n",
      "('n3', 0.97569877, 'Correct!')\n",
      "('n2', 0.9806651, 'Correct!')\n",
      "('n4', 0.98731905, 'Correct!')\n",
      "('n6', 0.99867576, 'Correct!')\n",
      "('n6', 0.9912889, 'Correct!')\n",
      "('n7', 0.99598795, 'Correct!')\n",
      "('n2', 0.9980089, 'Correct!')\n",
      "('n4', 0.9996519, 'Correct!')\n",
      "('n5', 0.99284714, 'Correct!')\n",
      "('n0', 0.99992, 'Correct!')\n",
      "('n4', 0.9919471, 'Correct!')\n",
      "('n2', 0.8582761, 'Correct!')\n",
      "('n2', 0.68529564, 'Correct!')\n",
      "('n9', 0.997042, 'Correct!')\n",
      "('n5', 0.987832, 'Correct!')\n",
      "('n3', 0.99884254, 'Correct!')\n",
      "('n2', 0.9957172, 'Correct!')\n",
      "('n3', 0.91383415, 'Correct!')\n",
      "('n5', 0.6668329, 'Correct!')\n",
      "('n5', 0.9983399, 'Correct!')\n",
      "('n4', 0.9834451, 'Correct!')\n",
      "('n0', 0.9967391, 'Correct!')\n",
      "('n8', 0.99878806, 'Correct!')\n",
      "('n7', 0.95161825, 'Correct!')\n",
      "('n6', 0.90691686, 'Correct!')\n",
      "('n9', 0.99098104, 'Correct!')\n",
      "('n6', 0.98327935, 'Correct!')\n",
      "('n2', 0.8850829, 'Correct!')\n",
      "('n4', 0.9431643, 'Correct!')\n",
      "('n3', 0.9990796, 'Correct!')\n",
      "('n1', 0.9329815, 'Correct!')\n",
      "('n4', 0.9967854, 'Correct!')\n",
      "('n9', 0.9981692, 'Correct!')\n",
      "('n7', 0.9920512, 'Correct!')\n",
      "('n1', 0.9992067, 'Correct!')\n",
      "('n6', 0.96152085, 'Correct!')\n",
      "('n1', 0.99975234, 'Correct!')\n",
      "('n5', 0.9954485, 'Correct!')\n",
      "('n5', 0.9634659, 'Correct!')\n",
      "('n7', 0.9911308, 'Correct!')\n",
      "('n8', 0.9946957, 'Correct!')\n",
      "('n6', 0.99274135, 'Correct!')\n",
      "('n8', 0.8222556, 'Correct!')\n",
      "('n5', 0.99486685, 'Correct!')\n",
      "('n7', 0.9919503, 'Correct!')\n",
      "('n4', 0.96554536, 'Correct!')\n",
      "('n6', 0.9882989, 'Correct!')\n",
      "('n3', 0.98770416, 'Correct!')\n",
      "('n1', 0.9999145, 'Correct!')\n",
      "('n0', 0.99961275, 'Correct!')\n",
      "('n4', 0.9988049, 'Correct!')\n",
      "('n7', 0.9979942, 'Correct!')\n",
      "('n0', 0.99803025, 'Correct!')\n",
      "('n3', 0.95417374, 'Correct!')\n",
      "('n7', 0.98804396, 'Correct!')\n",
      "('n7', 0.99859744, 'Correct!')\n",
      "('n2', 0.98542005, 'Correct!')\n",
      "('n7', 0.99615854, 'Correct!')\n",
      "('n7', 0.99222046, 'Correct!')\n",
      "('n9', 0.99585754, 'Correct!')\n",
      "('n4', 0.98059344, 'Correct!')\n",
      "('n8', 0.99592704, 'Correct!')\n",
      "('n9', 0.9902473, 'Correct!')\n",
      "('n0', 0.9993869, 'Correct!')\n",
      "('n1', 0.9995178, 'Correct!')\n",
      "('n1', 0.9954367, 'Correct!')\n",
      "('n5', 0.9400519, 'Correct!')\n",
      "('n8', 0.9997919, 'Correct!')\n",
      "('n5', 0.998329, 'Correct!')\n",
      "('n8', 0.9946719, 'Correct!')\n",
      "('n4', 0.99267477, 'Correct!')\n",
      "('n3', 0.9919876, 'Correct!')\n",
      "('n0', 0.99242777, 'Correct!')\n",
      "('n5', 0.70508075, 'Correct!')\n",
      "('n6', 0.96281177, 'Correct!')\n",
      "('n4', 0.9990957, 'Correct!')\n",
      "('n8', 0.9620383, 'Correct!')\n",
      "('n5', 0.97442436, 'Correct!')\n",
      "('n6', 0.99347115, 'Correct!')\n",
      "('n3', 0.99267536, 'Correct!')\n",
      "('n9', 0.57756686, 'Correct!')\n",
      "('n8', 0.9985807, 'Correct!')\n",
      "('n0', 0.9976878, 'Correct!')\n",
      "('n4', 0.9992454, 'Correct!')\n",
      "('n0', 0.99981254, 'Correct!')\n",
      "('n0', 0.9807421, 'Correct!')\n",
      "('n1', 0.9995696, 'Correct!')\n",
      "('n9', 0.88600916, 'Correct!')\n",
      "('n7', 0.985761, 'Correct!')\n",
      "('n0', 0.9991386, 'Correct!')\n",
      "('n0', 0.99932444, 'Correct!')\n",
      "('n3', 0.99886084, 'Correct!')\n",
      "('n0', 0.9924936, 'Correct!')\n",
      "('n8', 0.97433823, 'Correct!')\n",
      "('n6', 0.9924476, 'Correct!')\n",
      "('n1', 0.9939932, 'Correct!')\n",
      "('n2', 0.97932976, 'Correct!')\n",
      "('n7', 0.9978974, 'Correct!')\n",
      "('n8', 0.9969896, 'Correct!')\n",
      "('n5', 0.99649185, 'Correct!')\n",
      "('n0', 0.9977858, 'Correct!')\n",
      "('n8', 0.9977912, 'Correct!')\n",
      "('n5', 0.9885151, 'Correct!')\n",
      "('n7', 0.99525094, 'Correct!')\n",
      "('n4', 0.9817213, 'Correct!')\n",
      "('n4', 0.9837847, 'Correct!')\n",
      "('n6', 0.7406921, 'Correct!')\n",
      "('n3', 0.995823, 'Correct!')\n",
      "('n4', 0.99729544, 'Correct!')\n",
      "('n6', 0.9842584, 'Correct!')\n",
      "('n0', 0.99669063, 'Correct!')\n",
      "('n3', 0.99042106, 'Correct!')\n",
      "('n9', 0.98839885, 'Correct!')\n",
      "('n0', 0.9993869, 'Correct!')\n",
      "('n2', 0.9917589, 'Correct!')\n",
      "('n6', 0.606592, 'False! -Correct was: ', 'n2')\n",
      "('n4', 0.9797519, 'Correct!')\n",
      "('n3', 0.9987381, 'Correct!')\n",
      "('n1', 0.9996942, 'Correct!')\n",
      "('n7', 0.997106, 'Correct!')\n",
      "('n8', 0.9993987, 'Correct!')\n",
      "('n1', 0.9997837, 'Correct!')\n",
      "('n9', 0.72389966, 'Correct!')\n",
      "('n5', 0.9922909, 'Correct!')\n",
      "('n7', 0.95312774, 'Correct!')\n",
      "('n2', 0.99875927, 'Correct!')\n",
      "('n6', 0.98199826, 'Correct!')\n",
      "('n9', 0.9988549, 'Correct!')\n",
      "('n4', 0.98835236, 'Correct!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n5', 0.9853543, 'Correct!')\n",
      "('n2', 0.9703625, 'Correct!')\n",
      "('Accuracy: ', 1)\n"
     ]
    }
   ],
   "source": [
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n",
    "\n",
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "   \n",
    "    image_reader = tf.image.decode_jpeg(file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    \n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "    \n",
    "    return result\n",
    "\n",
    "model_file = 'retrained_model/output_graph.pb'\n",
    "label_file = 'retrained_model/output_labels.txt'\n",
    "input_layer = 'Placeholder'\n",
    "output_layer = 'final_result'\n",
    "\n",
    "#load graph\n",
    "graph = tf.Graph()\n",
    "graph_def = tf.GraphDef()\n",
    "with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "labels = load_labels(label_file)\n",
    "\n",
    "#shuffle test dataframe\n",
    "test_Tlearning = test.sample(frac=1)\n",
    "correct = 0    \n",
    "for index, row in test_Tlearning.iterrows():\n",
    "    t = read_tensor_from_image_file(row[\"path\"])\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "            input_operation.outputs[0]: t\n",
    "        })\n",
    "    results = np.squeeze(results)\n",
    "    \n",
    "    top_k = results.argsort()[-1:][::-1]\n",
    "    for i in top_k:\n",
    "        if (labels[i] == row[\"labels\"]):\n",
    "            print(labels[i], results[i], \"Correct!\")\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            print(labels[i], results[i], \"False! -Correct was: \", row[\"labels\"], \"Path:\", row[\"path\"])\n",
    "            \n",
    "\n",
    "acc = correct / len(test_paths)\n",
    "print(\"Accuracy: \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_labelled_input_fn(df, batch_size):\n",
    "    def input_fn():\n",
    "        image_list, label_list = df[\"path\"].tolist(), df[\"int\"].tolist()\n",
    "\n",
    "        def read_images_from_disk(input_queue):\n",
    "            label = input_queue[1]\n",
    "            file_contents = tf.read_file(input_queue[0])\n",
    "            example = tf.image.decode_jpeg(file_contents, channels=3)\n",
    "            example=tf.image.resize_images(example, [150, 150])\n",
    "            example=tf.reshape(example, [150, 150, 3]) \n",
    "            return example, label\n",
    "\n",
    "        images = tf.convert_to_tensor(image_list, dtype=tf.string)\n",
    "        labels = tf.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "\n",
    "        # Makes an input queue\n",
    "        input_queue = tf.train.slice_input_producer([images, labels], shuffle=True)\n",
    "\n",
    "        image, label = read_images_from_disk(input_queue)\n",
    "        image_batch, label_batch = tf.train.batch([image, label], batch_size=batch_size)\n",
    "        return {'images':  image_batch}, label_batch\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efc6c4a5d50>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './linear_model', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('images', shape=[150,150,3])]\n",
    "\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=10,\n",
    "    model_dir='./linear_model'\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 40\n",
    "TRAIN_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./linear_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 92.10341, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into ./linear_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3939168.5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7efc198f9390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=generate_labelled_input_fn(train, BATCH_SIZE),\n",
    "    steps=TRAIN_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-11-21:52:37\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./linear_model/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-11-21:53:49\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.33825, average_loss = 90258.18, global_step = 100, loss = 3610327.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.33825,\n",
       " 'average_loss': 90258.18,\n",
       " 'global_step': 100,\n",
       " 'loss': 3610327.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(\n",
    "    input_fn=generate_labelled_input_fn(test, BATCH_SIZE),\n",
    "    steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
