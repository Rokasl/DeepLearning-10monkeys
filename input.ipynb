{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ops",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bd53d1f93125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input/training/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named ops"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "warnings.resetwarnings()\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import csv\n",
    "\n",
    "train_dir = Path('input/training/')\n",
    "test_dir = Path('input/validation/')\n",
    "info = pd.read_csv(\"input/monkey_labels.txt\", names=['Label','Latin Name', 'Common Name','Train Images', 'Validation Images'], skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    images = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for training_dir_path in glob.glob(filename + \"/*\"):\n",
    "        label = info[\"Common Name\"][i].rstrip()\n",
    "        i=i+1\n",
    "        for image_path in glob.glob(os.path.join(training_dir_path, \"*.jpg\")):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image, (1, 1))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "            labels.append(label)\n",
    "            images.append(image)\n",
    "            paths.append(image_path)\n",
    "            \n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(labels)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    iencoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(iencoded)\n",
    "    \n",
    "    n = {'path': paths, 'labels':labels, 'int':integer_encoded}\n",
    "    d = {'images':images,'labels':labels, 'int':integer_encoded, 'hot': onehot_encoded.tolist()}\n",
    "\n",
    "    df = pd.DataFrame(n)\n",
    "    return df\n",
    "\n",
    "train = read_data(\"input/training\")\n",
    "train.to_csv('./input/train-paths-labels.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = tf.train.string_input_producer(['./input/train-paths-labels.csv'])\n",
    "textReader = tf.TextLineReader()\n",
    "_, csv_content = textReader.read(csv_path)\n",
    "# _, rows = reader.read_up_to(file_queue, num_records=100*100)\n",
    "\n",
    "record_defaults = [1], [\"\"], [\"\"]\n",
    "        \n",
    "columns = tf.decode_csv(csv_content, record_defaults=record_defaults)\n",
    "        \n",
    "labels = columns[0]\n",
    "paths = columns[2]\n",
    "# load images\n",
    "content = tf.read_file(paths)\n",
    "image = tf.image.decode_jpeg(content, channels=3)\n",
    "image = tf.reshape(image, [10,10,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DecodeJpeg_12:0\", shape=(50, 50, 3), dtype=uint8)\n",
      "Tensor(\"input_producer_21/Gather_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def read_labeled_image_list(image_list_file):\n",
    "    df = pd.read_csv(image_list_file)\n",
    "    return df[\"path\"].tolist(), df[\"int\"].tolist()\n",
    "\n",
    "def read_images_from_disk(input_queue):\n",
    "    label = input_queue[1]\n",
    "    file_contents = tf.read_file(input_queue[0])\n",
    "    example = tf.image.decode_jpeg(file_contents, channels=3)\n",
    "    example.set_shape([50, 50, 3])\n",
    "    return example, label\n",
    "\n",
    "# Reads pathes of images together with their labels\n",
    "image_list, label_list = read_labeled_image_list(\"./input/train-paths-labels.csv\")\n",
    "\n",
    "images = tf.convert_to_tensor(image_list, dtype=tf.string)\n",
    "labels = tf.convert_to_tensor(label_list, dtype=tf.int32)\n",
    "\n",
    "# Makes an input queue\n",
    "input_queue = tf.train.slice_input_producer([images, labels], shuffle=True)\n",
    "\n",
    "image, label = read_images_from_disk(input_queue)\n",
    "\n",
    "# Optional Preprocessing or Data Augmentation\n",
    "# tf.image implements most of the standard image augmentation\n",
    "# image = preprocess_image(image)\n",
    "# label = preprocess_label(label)\n",
    "\n",
    "# Optional Image and Label Batching\n",
    "image_batch, label_batch = tf.train.batch([image, label], batch_size=50)\n",
    "\n",
    "print(image)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_labelled_input_fn(csv_files, batch_size):\n",
    "    def input_fn():\n",
    "        file_queue = tf.train.string_input_producer(csv_files)\n",
    "        reader = tf.TextLineReader(skip_header_lines=1)\n",
    "#         _, rows = textReader.read(file_queue)\n",
    "#         _, rows = reader.read(file_queue)\n",
    "        _, rows = reader.read_up_to(file_queue, num_records=100*batch_size)\n",
    "        expanded_rows = tf.expand_dims(rows, axis=-1)\n",
    "     \n",
    "        shuffled_rows = tf.train.shuffle_batch(\n",
    "            [expanded_rows],\n",
    "            batch_size=batch_size,\n",
    "            capacity=20*batch_size,\n",
    "            min_after_dequeue=5*batch_size,\n",
    "            enqueue_many=True\n",
    "        )\n",
    "        \n",
    "        record_defaults = [[0], [\"\"], [\"\"]]\n",
    "        \n",
    "        columns = tf.decode_csv(shuffled_rows, record_defaults=record_defaults)\n",
    "        \n",
    "        labels = columns[0]\n",
    "        paths = columns[2]\n",
    "#         paths = tf.concat(columns[2:], axis=0)\n",
    "        \n",
    "        \n",
    "        # load images\n",
    "        content = tf.read_file(paths)\n",
    "        image = tf.image.decode_jpeg(content, channels=3)\n",
    "#         image = tf.cast(image, tf.float32) / 255.\n",
    "        image = tf.image.resize_images(image, [10, 10])\n",
    "#         image = tf.reshape(image, [1,1,3])\n",
    "\n",
    "        return {'images':  image}, labels\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
